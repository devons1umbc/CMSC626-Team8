# -*- coding: utf-8 -*-
"""Malware_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J7QeE5SZirkqwDydz-oFbDX4bAD__g8q
"""

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

dataset_path = '/content/drive/MyDrive/malware_dataset.csv'

import numpy as np
import pandas as pd
import tensorflow as tf

data = pd.read_csv(dataset_path)

data.head()

data.info()

data.columns

data["classification"].value_counts()

data['classification'] = data.classification.map({'benign':0, 'malware':1})
data.head()

data = data.sample(frac=1).reset_index(drop=True)
data.head()

import matplotlib.pyplot as plt
import seaborn as sns

sns.countplot(data["classification"])
plt.show()

corrMatrix = data.corr()
sns.heatmap(corrMatrix, annot=True)
plt.show()

X = data.drop(["hash","classification",'vm_truncate_count','shared_vm','exec_vm','nvcsw','maj_flt','utime'],axis=1)
Y = data["classification"]

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=1)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

input_size = 27

output_size = 2
hidden_layer_size = 256

model = tf.keras.Sequential([
    tf.keras.layers.Dense(hidden_layer_size, input_shape=(input_size,), activation='tanh'),
    tf.keras.layers.Dense(hidden_layer_size, activation='tanh'),
    tf.keras.layers.Dense(hidden_layer_size, activation='tanh'),
    tf.keras.layers.Dense(hidden_layer_size, activation='tanh'),
    tf.keras.layers.Dense(hidden_layer_size, activation='tanh'),
    tf.keras.layers.Dense(hidden_layer_size, activation='tanh'),
    tf.keras.layers.Dense(output_size, activation='softmax')
])

model.summary()

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

batch_size = 200

max_epochs = 25


early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)

result = model.fit(x=x_train,
                   y=y_train,
                   batch_size=batch_size,
                   epochs=max_epochs,
                   verbose=1,
#                    callbacks=[early_stopping],
                   validation_split=0.2)

# Visualize the result
acc = result.history['accuracy']
val_acc = result.history['val_accuracy']
loss = result.history['loss']
val_loss = result.history['val_loss']

epochs = range(1, len(acc) + 1)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
sns.set_style("white")
plt.suptitle('Train history', size = 15)

ax1.plot(epochs, acc, "bo", label = "Training acc")
ax1.plot(epochs, val_acc, "b", label = "Validation acc")
ax1.set_title("Training and validation acc")
ax1.legend()

ax2.plot(epochs, loss, "bo", label = "Training loss", color = 'red')
ax2.plot(epochs, val_loss, "b", label = "Validation loss", color = 'red')
ax2.set_title("Training and validation loss")
ax2.legend()

plt.show()

test_loss, test_accuracy = model.evaluate(x_test, y_test)

print('\nTest loss: {0:.6f}. Test accuracy: {1:.6f}%'.format(test_loss, test_accuracy*100.))

from keras.optimizers import SGD
sgd = SGD(learning_rate=0.01)
model.compile(optimizer = sgd, loss = "sparse_categorical_crossentropy", metrics=['accuracy'])

result = model.fit(x=x_train,
                   y=y_train,
                   batch_size=batch_size,
                   epochs=30,
                   verbose=1,
                   initial_epoch=20, #start from epoch 11
                   callbacks=[early_stopping], #prevent overfitting
                   validation_split=0.2)

ctest_loss, test_accuracy = model.evaluate(x_test, y_test)

print('\nTest loss: {0:.6f}. Test accuracy: {1:.6f}%'.format(test_loss, test_accuracy*100.))

from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

rfc_model = RandomForestClassifier(
    n_estimators = 50,
    max_depth = 8
)

rfc_model.fit(x_train, y_train)

rfc_xtest_pred = rfc_model.predict(x_test)
rfc_xtrain_pred = rfc_model.predict(x_train)

rfc_xtest_accuracy = accuracy_score(y_test, rfc_xtest_pred)
rfc_xtrain_accuracy = accuracy_score(y_train, rfc_xtrain_pred)

print(f"X test Accuracy = {rfc_xtest_accuracy * 100} %")
print(f"X train Accuracy = {rfc_xtrain_accuracy * 100} %")

print(classification_report(y_test, rfc_xtest_pred))